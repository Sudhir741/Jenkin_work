Topic1: Introduction

Terraform ( Infrastructure As A Code IaaC) ::

	Why we use Terraform and not Chef, Puppet, Ansible, SaltStack, or CloudFormation

	If you search the Internet for “infrastructure-as-code”, it’s pretty easy to come up with 
	a list of
	 the most popular tools:

	Chef
	Puppet
	Ansible
	SaltStack
	CloudFormation
	Terraform


	All the above tools helps us to manage our infrastructure in the form of code. 
	But question is simple why 
	should we choose "terraform" than all these. If you observe all the above tools 
	are opensource and they 
	have their own communities and the contribution & one more thing is they all are 
	enterprize tools.

	Even we have "cloud formation" for automating the things with AWS than terraform. 
	but question remains same 
	why terraform ??

	Configuration Management vs Orchestration ::

	The above mentioned tools except "CloudFormation & Terraform" all other tools are 
	basically configuration 
	management tools.

	Which means that they are used to manage and install the s/w or helps to maintain a s
	tate of the particular 
	macine. 

	But "Terraform" & "CloudFormation" are the Orchestration tools which means that they are desinged to provison
	 the machines & their infrastructure. Once the machine is builded you can
	use the configuration management tools for performing your task.

	Mutable Infrastructure vs Immutable Infrastructure ::

	Mutable --> Configuration management tools
	using configuration management tools, we can deploy the new software versions based up on the environement we
	are choosing. But if you observe each server will be having a seperate
	version based up on the environement.


	Immutable --> Orchestration tools
	But if you are choosing the Orchestration tools you can simply maintain all the servers with a single version 
	of OS. Its simple create a simple OS image and start deploy the servers as per the requirement and all your 
	old machines will be replaced with the newly builded machines and all the machines will have same version of 
	the package installed !!



	Procedural vs Declarative ::

	Procedural approach means if you want to achieve some thing you need to mention the things in an programatic approach. "Chef & Ansible" works on the same.

	But in Declarative approach you no need to worry about flow it will automatically gets the respective informaiton based up the resource what we are choosing. 

	For example if you want to create 10 servers with app version v1 then the code for different tools will be like below.

	using Ansible : (Procedural approach)

	- ec2:
		count: 10
		ami: app-v1
		instance_type: t2.micro
		

	Using terraform : (Declarative)

	resource "aws_instance" "example" {
	  count = 10
	  ami = "ami-v1"
	  instance_type = "t2.micro"
	}


	Till now its fine no much changes in both the configuration. But question is what will happen if the load is high and if you want to add 5 more servers. 

	Using Ansible you need to specify the code like below.

	- ec2:
		count: 15
		ami: app-v1
		instance_type: t2.micro
		
	Soon after executing this code, you will get a 15 more servers along with 10 machines so total will be 25 servers. But your desire state is to have only 5 machines with out changing 
	the code. Which means that you need to again re-write the entire code and find the previous machines and has to do all the other stuff.

	Using Terraform you need to specify the code like below.

	resource "aws_instance" "exampe" {
		count = 15
		ami = "ami-v1"
		instance_type = "t2.micro"
		}
		
	Now what Terraform will do it, it won't create 15 more servers it will simply create 5 servers because it is well aware of the current state what ever it is having. 
	Hence you no need to break you head to write new code.


	Disadvantages:

	Of course, there are downsides to declarative languages too. Without access to a full
	 programming language, your expressive power is limited. For example, some types of 
	infrastructure changes, such as a rolling, zero-downtime deployment, are hard to express
	 in purely declarative terms. Similarly, without the ability to do “logic” 
	(e.g. if-statements, loops), creating generic, reusable code can be tricky (especially in
	 CloudFormation). 

	Client/Server Architecture vs Client-Only Architecture ::

	Chef,puppet & salt stack are purely based on "Client/Server". Which indeed there are many
	 hiccups when you are dealing with these tools, like 

	1. you need to install the client in all the machines in order to get the desired state as 
	per the requirement
	2. you should require a manageble server which should give the instructions to the client
	 machines. 
	3. you will get all the issues with the network,client,management and etc.

	Ansible,CloudFormation & Terraform are purely client-only Architecture, which in deed you 
	no need to install any agents as part of your machines in order to do the management. 

	CloudFormation is also client/server, but AWS handles all the server details so transparently,
	 that as an end user, you only have to think about the client code.
	The Ansible client works by connecting directly to your servers over SSH
	Terraform uses cloud provider APIs to provision infrastructure, so there are no new 
	authentication mechanisms beyond what you’re using with the cloud provider already, and 
	there is no need for direct access to your servers

	Final Conclusion:

	Of course, Terraform isn’t perfect. It’s younger and less mature than all the other tools on the list: whereas Puppet came out in 2005, Chef in 2009, SaltStack and CloudFormation in 
	2011, and Ansible in 2012,
	Terraform came out just 4 years ago, in 2014. 
	Bugs are relatively common (e.g. there are over 800 open issues with the label “bug”), although the vast majority are harmless eventual consistency issues that go away when you 
	rerun Terraform


Topic2: Installation and Configuration:

	https://www.terraform.io/downloads

	Amazon Linux:

	sudo yum install -y yum-utils
	sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo
	sudo yum -y install terraform

	Creating connection between CLI & AWS API ::

	[root@terraform basics]# aws configure
	AWS Access Key ID [None]: AKIAVEWARMEZ4JG77O25
	AWS Secret Access Key [None]: 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
	Default region name [None]: us-east-1
	Default output format [None]: json

	export AWS_DEFAULT_REGION="us-east-1"

	lets play around our terraform commands ::

	:: Explain in detail about the documentation page ::

Topic 3 :: Terraform Commands - init,plan,validate,apply,destroy
	
	show them the creation of keypair 
	explain in detail about the terraform commands 
	explain about provider section & new formats like importance of versions 
	tell them what happens if in case of destroy 

	useful Commands::

	apply: Builds or changes infrastructure
	console: Interactive console for Terraform interpolations
	destroy: Destroys Terraform-managed infrastructure
	fmt: Rewrites configuration files to canonical format
	get: Downloads and installs modules for the configuration
	graph: Creates a visual graph of Terraform resources
	import: Imports existing infrastructure into Terraform
	init: Initializes a new or existing Terraform configuration
	output: Reads an output from a state file
	plan: Generates and shows an execution plan
	providers: Prints a tree of the providers used in the configuration
	push: Uploads this Terraform module to Terraform Enterprise to run
	refresh: Updates local state file against real resources
	show: Inspects Terraform state or plan
	taint: Manually marks a resource for recreation
	untaint: Manually unmarks a resource as tainted
	validate: Validates the Terraform files
	version: Prints the Terraform version
	workspace: Workspace management


	HashiCorp Configuration Language ::

	Refernces :
	https://www.terraform.io/docs/providers/docker/r/container.html
	https://www.terraform.io/docs/configuration-0-11/syntax.html
	https://www.terraform.io/docs/configuration-0-11/interpolation.html

	If you want to access the variables value then you can use the below syntax

	"${variable.attribute}"


Topic 4: Variables & Data types 
	Explain in detail how to define a variable 
	Explain in detail about list & map (dictionary) && how to access the values from them.
	Syntax:
		variable "your-var-name" {
				default = "any default values"
				type = (optional) string
				
			}

	How to access the value of a varirable
	Syntax:
		output "name-on-screen" {
			value  = "${var.varname}"
						(((OR)))
			value = "${resourcename.resource-local-name.idname}"
		}		
		
	Types of variables 
		string
		list(<TYPE>)
		set(<TYPE>)
		map(<TYPE>)
		object({<ATTR NAME> = <TYPE>, ... })
		tuple([<TYPE>, ...])
	Explain in detail about data types with examples 
		string data type
		List data type 
		map data type 
		Object data type 
		
			variable "rg_name" {
			type = object({age=number,name=string})
			default = {
					age = 32
					name = "shahan"
				}
			}

Topic5: Working with variables 
	Diff types of variable declarations
		default
		taking values from end user (don't give default section)
		command line arguments (-var)
		passing values from tfvars (-var-file)
		using locals
			locals {
				tags = {
						env = local.env_name
						owner = local.owner_name
				}
			}	

Topic6: Code seggregation
	Explain in detail about the seggregation of code like variables.tf,main.tf,myvars.tfvars,locals.tf,outputs.tf
	

Topic7: Meta arguments 
	Explain in detail about the meta arguments creating S3 service
		depends_on
		count & index 
		for_each
		count with element & index 
		
Topic8: Working with infrastructure
	Make sure that you are creating infrastructure for
		s3,vpc,ec2
	Explain in detail how to write code in same folder 
	
Topic9: Working with modules 
	Create seperate modules for 
		s3,vpc,ec2 
	Combile everything & try to build the application code using modules 

	
Topic10: Working with workspaces 
	Show how to create multiple environments for the applications using modules & same code 
	workspace commands ::

		terraform workspace list
		terraform workspace new prod
		terraform workspace select prod
		terraform plan -out prodplan -var env=prod
		terraform apply prodplan

Topic11: Protect state file 
	Ref: https://www.terraform.io/language/settings/backends/s3
	Explain the use case of statefile 
	What happens if we loose it or corrupt it 
	Add backend to provider section:
	
		terraform {
		  required_providers {
			azurerm = {
			  source = "hashicorp/azurerm"
			  version = "3.9.0"
			}
		  }

	s3statebackup.tf

	terraform {
	  backend "s3" {
		bucket = "protect-s3-statefile"
		key    = "terraform.tfstate"
		region = "us-east-1"
		dynamodb_table = "protect-s3-statefile"
	  }
	}



========================

Practise Example :

Autoscalling configuration ::

Creating AWS Autoscalling so that, even thought the server is crashes we will have other instances will be up and running fine. 


1. Gathering all the availability zones

2. Configuring security group

3. Creating the launch configuration

4. Creating Autoscalling Group

5. Creating ELB

6. Printing the load balencer dns name

Final Code:

[root@terraform asg]# cat main.tf
provider "aws" {
        region = "eu-west-2"
        profile = "default"
        }


# Gathering availability zones

data "aws_availability_zones" "all" {}

# Creating security Group

resource "aws_security_group" "my_security_group" {
        name = "my_security_group"
        ingress {
            from_port   = 0
            to_port     = 0
            protocol    = "-1"
            cidr_blocks = ["0.0.0.0/0"]
          }

          egress {
            from_port       = 0
            to_port         = 0
            protocol        = "-1"
            cidr_blocks     = ["0.0.0.0/0"]
        }
        tags {
                Name = "Allow All"
        }

}


#Creating the launch configuration

resource "aws_launch_configuration" "my-launch-configuration" {
        name = "my-launch-configuration"
        image_id = "ami-403e2524"
        instance_type = "t2.micro"
        security_groups = ["${aws_security_group.my_security_group.id}"]
        user_data = <<-EOF
              #!/bin/bash
              yum install httpd -y
              chkconfig httpd on
              echo "Hello, World" >> /var/www/html/index.html
              service httpd restart
              EOF
}
# Creating Autoscaling Group

resource "aws_autoscaling_group" "my_autoscaling_group" {
        availability_zones = ["${data.aws_availability_zones.all.names}"]
        launch_configuration = "${aws_launch_configuration.my-launch-configuration.id}"
        min_size = 2
        max_size = 4
        health_check_type = "ELB"
        load_balancers = ["${aws_elb.my-elb.id}"]
        tag {
                key = "Name"
                value = "terraform-example-asg"
                propagate_at_launch = true
         }


}

# Creating Loadbalencer

resource "aws_elb" "my-elb" {
        name = "my-elb"
        availability_zones = ["${data.aws_availability_zones.all.names}"]
        listener {
            instance_port     = 80
            instance_protocol = "http"
            lb_port           = 80
            lb_protocol       = "http"
          }
        health_check {
            healthy_threshold   = 2
            unhealthy_threshold = 2
            timeout             = 3
            target              = "TCP:80"
            interval            = 30
          }

}

# Displaying the elb dns name

output "dns_name" {
        value = "${aws_elb.my-elb.dns_name}"
        }

==========================
Module Output Format ::

output "mys3_bucket_name" {

        value = "${module.storage.mys3_bucket_name}"
}

output "mypub_ip1" {
        value = "${module.server.mypub_ip}"
}